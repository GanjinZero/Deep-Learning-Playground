{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Modern NLP in biomedical\n",
    "Attention, Transformers, BERT, BioBERT, PubMedBERT, CODER, KeBioLM\n",
    "\n",
    "Author: Yuan Zheng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Layers in neural network\n",
    "\n",
    "Input: \n",
    "Batch_size \\* k\n",
    "$$x = (x_1, x_2, ..., x_k) \\in \\mathbf{R}^k$$\n",
    "\n",
    "\n",
    "Linear layer\n",
    "\n",
    "\n",
    "Output:\n",
    "Batch_size \\* n\n",
    "$$y = (y_1, y_2, ..., y_n) \\in \\mathbf{R}^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Layers in neural network\n",
    "\n",
    "Input: \n",
    "Batch_size \\* Time_step \\* k\n",
    "$$x_i = (x_{1i}, x_{2i}, ..., x_{ki}) \\in \\mathbf{R}^k$$\n",
    "\n",
    "\n",
    "RNN,\n",
    "GRU,\n",
    "LSTM,\n",
    "CNN\n",
    "\n",
    "Output:\n",
    "Batch_size \\* Time_step \\* n\n",
    "$$y_i = (y_{1i}, y_{2i}, ..., y_{ni}) \\in \\mathbf{R}^n$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Attention Mechanism\n",
    "\n",
    "## Paper\n",
    "Attention is all you need.\n",
    "\n",
    "## Query, Key, Value\n",
    "![Attention](https://pic2.zhimg.com/80/v2-f0e3e2fa8493252bfd09a586c30b042f_1440w.jpg?source=1940ef5c)\n",
    "\n",
    "$$score = QK^T$$\n",
    "$$alpha = Softmax(QK^T)$$\n",
    "$$y = alpha * V$$\n",
    "\n",
    "For example:\n",
    "$$k_0 = (1, 0, 0, 0) = v_0$$\n",
    "$$k_1 = (0, 1, 1, 1) = v_1$$\n",
    "$$k_2 = (1, 1, 1, 1) = v_2$$\n",
    "$$q = (1, 0, 1, 1)$$\n",
    "\n",
    "$$score_0 = (q, k_0) = 1$$\n",
    "$$score_1 = (q, k_1) = 2$$\n",
    "$$score_2 = (q, k_2) = 3$$\n",
    "\n",
    "$$alpha = (\\frac{e}{e+e^2+e^3},\\frac{e^2}{e+e^2+e^3},\\frac{e^3}{e+e^2+e^3}) = (0.09, 0.25, 0.66)$$\n",
    "\n",
    "$$y = 0.09 * v_0 + 0.25 * v_1 + 0.66 * v_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Self-Attention\n",
    "\n",
    "Input: $$x$$\n",
    "\n",
    "Parameters: $$W_Q, W_K, W_V$$\n",
    "\n",
    "$$Q = W_Q * x$$\n",
    "$$K = W_K * x$$\n",
    "$$V = W_V * x$$\n",
    "\n",
    "Output: $$y = softmax(QK^T)V=softmax(W_Qxx^TW_K^T)W_Vx$$\n",
    "\n",
    "Important variants: Scaled self attention\n",
    "$$y = softmax(QK^T/\\sqrt{d_k})V$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# What is self attention actually doing?\n",
    "\n",
    "![self](self.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-head self attention\n",
    "![multi-head](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transformers\n",
    "State of the art architecture of NLP and CV!\n",
    "![trans](transformer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Encoder layer\n",
    "\n",
    "- Positional Encoding\n",
    "![pos](https://pic1.zhimg.com/v2-c9b34779e00ff95c10059df2b432b23b_r.jpg?source=1940ef5c)\n",
    "\n",
    "- Add & Norm: LayerNorm(x + MultiHeadAttention(x))\n",
    "\n",
    "- Feed forward: Two-layer linear layers\n",
    "\n",
    "Transformers = 6 \\* Encoder Layer + 6 \\* Decoder Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bert\n",
    "BERT = 12 * Encoder Layer\n",
    "\n",
    "GPT-1 = 12 * Decoder Layer\n",
    "\n",
    "GPT-3 = 96 * Decoder Layer\n",
    "\n",
    "## Input & Output\n",
    "Input1: [CLS] There is a [MASK] in my bag. [SEP] It is Xiao ##mi. [SEP]\n",
    "\n",
    "Input2: [CLS] There is a [MASK] in my bag. [SEP]\n",
    "\n",
    "Output:\n",
    "\n",
    "[CLS] -> Next setence. \n",
    "[MASK] -> phone\n",
    "\n",
    "## Architecture\n",
    "\n",
    "- Embedding Layer\n",
    "![embed](https://pic4.zhimg.com/80/v2-4f9f62a7776afcdd1e1c99dfa57b965f_1440w.jpg)\n",
    "\n",
    "- Arch\n",
    "![Arch](https://pic1.zhimg.com/80/v2-9979c95d66a71a720207a48311702430_1440w.jpg)\n",
    "\n",
    "## Pretraining Task\n",
    "Next Sentence Classification: Not important.\n",
    "\n",
    "Masked Language Modelling: Recover masked tokens in sentence. Require model to understand the sentence meaning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Memory issue for BERT\n",
    "\n",
    "It is a 12-layer transformer model. Really Big.\n",
    "Max batch-size for 12GB graphic card:\n",
    "\n",
    "| Sequence length | Batch-size |\n",
    "| :--:|:--:|\n",
    "|64|64|\n",
    "|128|32|\n",
    "|256|16|\n",
    "|512|6|\n",
    "\n",
    "You cannot input a sequence longer than 512 into BERT directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to train a NLP model on a specific NLP task?\n",
    "Tasks include:\n",
    "- Text classification\n",
    "- Named Entity Recognization\n",
    "- Question Answering\n",
    "- etc.\n",
    "\n",
    "## Before Pretrained Language Model (PLM)\n",
    "- Train/use a word2vec model as word representation\n",
    "- Train a complex model (e.g. lots of LSTM layers) for specific NLP task\n",
    "\n",
    "## After PLM\n",
    "- Train/use a PLM as word/sentence representation (**Pre-training**)\n",
    "- Fine-tune a simple model (i.e. a single linear layer) for specific NLP task (**Fine-tuning**)\n",
    "- You should not freeze the PLM parameter!\n",
    "\n",
    "Bert performance >> LSTM\n",
    "\n",
    "![fine-tune](https://pic2.zhimg.com/v2-f576d9d19c9dcac1c6ee6ea28ea7a2d9_r.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.2\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)\n",
    "\n",
    "# How to load a pretrained model?\n",
    "# Use its name, or download it to your local folder.\n",
    "# Find model names on https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# PLM for biomedical\n",
    "Bert, **BioBert**, ClinicalBert, SciBert, BlueBERT, **PubMedBERT**, **KeBioLM**\n",
    "\n",
    "- Bert: Original Bert\n",
    "- BioBert: First biomedical bert, trained on PubMed\n",
    "- ClinicalBert: Trained on PubMed + Mimic3\n",
    "- SciBert: Trained on PubMed + arxiv\n",
    "- BlueBERT: Trained on PubMed + Mimic3\n",
    "- PubMedBERT: New vocabulary, trained on PubMed\n",
    "- KeBioLM: Integrate entity knowledge, trained on PubMed https://arxiv.org/abs/2104.10344"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![result](./1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d194e31e1214b4593f3f2736edd2732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440472042.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "# How to load them?\n",
    "\n",
    "# name of other models:\n",
    "# Original bert: bert-base-cased\n",
    "# BioBERT: dmis-lab/biobert-v1.1\n",
    "# ClinicalBERT: emilyalsentzer/Bio_ClinicalBERT\n",
    "# SciBERT: allenai/scibert_scivocab_uncased\n",
    "# BlueBERT: bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12\n",
    "# KeBioLM: https://github.com/GanjinZero/KeBioLM\n",
    "# More details for KeBioLM please ask me\n",
    "\n",
    "model = AutoModel.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract')\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[2, 3732, 2517, 3], [2, 9919, 3602, 1063, 11, 4356, 1015, 12, 1744, 42, 2964, 4591, 16, 8236, 5493, 2014, 1685, 10719, 1690, 2978, 13222, 3]], 'token_type_ids': [[0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "---\n",
      "[['[CLS]', 'pubmed', 'central', '##®', '(', 'pm', '##c', ')', 'is', 'a', 'free', 'full', '-', 'text', 'arch', '##ive', 'of', 'biomedical', 'and', 'life', 'sciences', '[SEP]']]\n"
     ]
    }
   ],
   "source": [
    "# BERT Tokenizer\n",
    "sentence = ['bm ii', 'PubMed Central® (PMC) is a free full-text archive of biomedical and life sciences']\n",
    "tokenize = tokenizer(sentence)\n",
    "print(tokenize)\n",
    "word_idx = tokenize['input_ids'][1]\n",
    "print(\"---\")\n",
    "print([tokenizer.convert_ids_to_tokens(word_idx)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    2,  3732,  2517,     3,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "             0,     0],\n",
      "        [    2,  9919,  3602,  1063,    11,  4356,  1015,    12,  1744,    42,\n",
      "          2964,  4591,    16,  8236,  5493,  2014,  1685, 10719,  1690,  2978,\n",
      "         13222,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "---\n",
      "(tensor([[[-8.1338e-01,  5.5416e-01,  4.1603e-01,  ...,  2.8464e-01,\n",
      "           5.4926e-02,  1.9964e-01],\n",
      "         [-1.6601e-01,  5.0937e-01,  1.0445e+00,  ..., -2.6240e-01,\n",
      "           7.8138e-01, -3.0793e-01],\n",
      "         [-1.8830e+00,  3.4614e-01,  2.2237e-01,  ..., -1.5059e-01,\n",
      "           1.6797e-01,  2.1651e-01],\n",
      "         ...,\n",
      "         [-6.9826e-01,  4.1187e-01,  1.8163e-03,  ..., -5.5871e-01,\n",
      "          -2.2124e-01, -3.7387e-02],\n",
      "         [-5.8367e-01,  3.6325e-01,  2.1144e-01,  ..., -3.5593e-01,\n",
      "          -8.5283e-02, -9.4153e-02],\n",
      "         [-6.0410e-01,  2.2312e-01,  3.2557e-01,  ..., -2.6152e-01,\n",
      "           4.3260e-02, -2.7107e-01]],\n",
      "\n",
      "        [[-6.8755e-01,  2.8057e-01,  1.0962e+00,  ..., -7.0970e-02,\n",
      "           7.0387e-02, -1.5061e-01],\n",
      "         [-6.2135e-02,  3.7038e-01,  1.3061e+00,  ...,  6.2594e-01,\n",
      "          -6.8117e-01, -2.4973e-01],\n",
      "         [-3.1611e-01,  4.3223e-01,  1.2578e+00,  ...,  6.9200e-01,\n",
      "          -7.8779e-01, -5.0163e-01],\n",
      "         ...,\n",
      "         [-5.1663e-01,  3.3251e-01,  5.6451e-01,  ..., -1.6087e-01,\n",
      "           8.1592e-01, -2.8076e-01],\n",
      "         [-1.0574e+00,  3.2996e-01,  2.0432e-01,  ...,  7.9987e-02,\n",
      "           5.3360e-02,  1.3629e+00],\n",
      "         [-6.9488e-01,  1.3008e-01,  1.4785e+00,  ...,  2.1986e-01,\n",
      "          -5.5358e-02, -5.0132e-01]]], grad_fn=<NativeLayerNormBackward>), tensor([[ 0.9014, -0.9247,  0.9945,  ...,  0.2915, -0.9665,  0.4283],\n",
      "        [ 0.9419, -0.4929,  0.9629,  ..., -0.1006,  0.4372, -0.0786]],\n",
      "       grad_fn=<TanhBackward>))\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction\n",
    "# Bert is not fit for sentence representation directly!\n",
    "tokenize = tokenizer(sentence, padding=True, return_tensors=\"pt\")\n",
    "print(tokenize)\n",
    "output = model(**tokenize)\n",
    "print(\"---\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 22, 768])\n",
      "torch.Size([2, 768])\n",
      "torch.Size([2, 768])\n"
     ]
    }
   ],
   "source": [
    "print(output[0].shape) # Word Representation\n",
    "print(output[1].shape) # Sentence Representation\n",
    "\n",
    "h = model(**tokenize)[1]\n",
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A general pipeline of training PyTorch Model\n",
    "\n",
    "- Create Dataset, Dataloader\n",
    "\n",
    "- Create Model, Optimizer\n",
    "\n",
    "    **In this tutorial, we only care about model and optimizer related to BERT.**\n",
    "\n",
    "- For each training step:\n",
    "    - fetch a batch of data\n",
    "    - feedforward\n",
    "    - backward\n",
    "    \n",
    "- Evaluation, Save model, Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6538, -0.0370, -0.2952],\n",
      "        [ 0.6350,  0.0014, -0.2340]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Design a new model based on BERT\n",
    "from torch import nn\n",
    "\n",
    "class BertSentenceClassifier(nn.Module):\n",
    "    def __init__(self, init_model, class_count=10):\n",
    "        super(BertSentenceClassifier, self).__init__()\n",
    "        self.bert = AutoModel.from_pretrained(init_model)\n",
    "        self.classifier = nn.Linear(768, class_count)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, input_ids, label=None):\n",
    "        # input_ids: batch_size * sentence_length\n",
    "        h = self.bert(input_ids)[1] # batch_size * 768\n",
    "        predict_y = self.classifier(h) # batch_size * class_count\n",
    "        if label is not None:\n",
    "            loss = self.loss_fn(predict_y, label)\n",
    "            return predict_y, loss\n",
    "        return predict_y, 0.0\n",
    "    \n",
    "classifier = BertSentenceClassifier(\"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\", class_count=3)\n",
    "input_ids = tokenizer(sentence, padding=True, return_tensors=\"pt\")['input_ids']\n",
    "predict_y, _ = classifier(input_ids)\n",
    "print(predict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Optimizer and Scheduler for fine-tuning BERT\n",
    "\n",
    "- Using AdamW as the optimizer for default\n",
    "- Small learning rate among 1e-5 ~ 5e-5\n",
    "- Warmup & Linear Decay\n",
    "    - 0 - 10% steps linear warmup\n",
    "    - 10% - 100% steps linear decay\n",
    "\n",
    "    ![decay](https://img-blog.csdnimg.cn/20200721131948457.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3F4cXN1bnNoaW5l,size_16,color_FFFFFF,t_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-5e058617ded9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m optimizer_grouped_parameters = [\n\u001b[0;32m      8\u001b[0m     {\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;34m\"params\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mno_decay\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;34m\"weight_decay\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     },\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "learning_rate = 5e-5\n",
    "weight_decay = 0.01\n",
    "adam_epsilon = 1e-8\n",
    "t_total = 1000\n",
    "\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in classifier.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\"params\": [p for n, p in classifier.named_parameters() if any(\n",
    "        nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters,\n",
    "                  lr=learning_rate,\n",
    "                  eps=adam_epsilon)\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=int(0.1 * t_total), num_training_steps=t_total\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CODER\n",
    "Cross-Lingual Medical Term Representation via Knowledge Graph Contrastive Learning\n",
    "https://arxiv.org/abs/2011.02947\n",
    "![coder](2.png)\n",
    "\n",
    "CODER is useful for **term** representation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![coder3](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Features for CODER:\n",
    "- Multilingual\n",
    "- Pretrained for term normalization with synonym and relation knowledge\n",
    "- Dual Contrastive Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45b785808f924122984bd9f03249dc35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# How to load CODER?\n",
    "# English version: GanjinZero/UMLSBert_ENG\n",
    "# Multilingual version: GanjinZero/UMLSBert_ALL\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "coder = AutoModel.from_pretrained('GanjinZero/UMLSBert_ALL')\n",
    "coder_tok = AutoTokenizer.from_pretrained('GanjinZero/UMLSBert_ALL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.7842, 0.7475, 0.2809, 0.7848],\n",
      "        [0.7842, 1.0000, 0.6829, 0.2937, 0.7063],\n",
      "        [0.7475, 0.6829, 1.0000, 0.3585, 0.7391],\n",
      "        [0.2809, 0.2937, 0.3585, 1.0000, 0.3581],\n",
      "        [0.7848, 0.7063, 0.7391, 0.3581, 1.0000]], grad_fn=<MmBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Feature Extraction & Term Similarity\n",
    "sen = ['背痛', 'backache', 'dorsalgia', 'heart attack', 'Rückenschmerzen']\n",
    "tokenized = coder_tok(sen, padding=True, return_tensors=\"pt\")\n",
    "h = coder(**tokenized)[1]\n",
    "h_norm = h / torch.norm(h, 2, dim=1).unsqueeze(-1)\n",
    "print(torch.mm(h_norm, h_norm.t()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# HW1\n",
    "Train a text classifier based on BERT model and thucnews\n",
    "\n",
    "# HW2\n",
    "Define a function using CODER\n",
    "```python\n",
    "def retrieve_most_similar(word, dictitionary):\n",
    "    # sort dictionarty based on similarity between word and dictionary\n",
    "    # you should consider the count of words in dictionarty is larger than general batch-size\n",
    "    return sorted_dictionarty\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
